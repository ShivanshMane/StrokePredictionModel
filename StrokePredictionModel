---
title: "Build and deploy a stroke prediction model using R"
date: "`r Sys.Date()`"
output: html_document
author: "Shivansh Mane!"
---

# About Data Analysis Report

This RMarkdown file contains the report of the data analysis done for the project on building and deploying a stroke prediction model in R. It contains analysis such as data exploration, summary statistics and building the prediction models. The final report was completed on `r date()`. 

**Data Description:**

According to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths.

This data set is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relevant information about the patient.


# Task One: Import data and data preprocessing

## Load data and install packages

```{r}
# Install required packages if not installed
install.packages(c("tidyverse", "tidymodels", "vetiver", "parsnip", "recipes", "rsample", "plumber"))
install.packages("ranger")

# Load the necessary libraries
library(tidyverse)
library(tidymodels)
library(vetiver)
library(parsnip)
library(recipes)
library(rsample)
library(plumber)
library(ranger)

# Load dataset
stroke_data <- read.csv("healthcare-dataset-stroke-data.csv")

# Display the first few rows of the dataset
head(stroke_data)


# Handling missing values (if any)
stroke_data <- stroke_data %>% drop_na()

# Convert categorical variables to factors
stroke_data <- stroke_data %>%
  mutate(across(where(is.character), as.factor))

# Feature Engineering - Normalization and Encoding
stroke_recipe <- recipe(stroke ~ ., data = stroke_data) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  prep()

# Apply transformations
prepped_data <- bake(stroke_recipe, new_data = stroke_data)



```


## Describe and explore the data

```{r}
# Check structure of dataset
glimpse(stroke_data)

# Summary statistics
summary(stroke_data)

# Check for missing values
colSums(is.na(stroke_data))

# Visualizing the distribution of target variable
ggplot(stroke_data, aes(x = factor(stroke))) +
  geom_bar(fill = "steelblue") +
  labs(title = "Stroke Distribution", x = "Stroke", y = "Count")

```



# Task Two: Build prediction models

```{r}
# Convert stroke to a factor (Fix for classification error)
stroke_data$stroke <- as.factor(stroke_data$stroke)

# Verify conversion
str(stroke_data)

# Splitting data into training and testing sets
set.seed(123)
data_split <- initial_split(stroke_data, prop = 0.8, strata = stroke)
train_data <- training(data_split)
test_data <- testing(data_split)

# Define a Random Forest model
stroke_model <- rand_forest(mtry = 5, trees = 1000, mode = "classification") %>%
  set_engine("ranger") %>%
  fit(stroke ~ ., data = train_data)



```




# Task Three: Evaluate and select prediction models

```{r}
# Predict on test data
stroke_predictions <- predict(stroke_model, test_data, type = "class") %>%
  bind_cols(test_data)

# Confusion matrix
conf_mat(stroke_predictions, truth = stroke, estimate = .pred_class)

# Model performance metrics
metrics <- stroke_predictions %>%
  metrics(truth = stroke, estimate = .pred_class)

print(metrics)


```



# Task Four: Deploy the prediction model

```{r}
# Ensure stroke column is a factor
train_data$stroke <- as.factor(train_data$stroke)

# Define a fresh Random Forest model specification (unfitted)
stroke_model_spec <- rand_forest(mtry = 5, trees = 1000, mode = "classification") %>%
  set_engine("ranger")

# Create a workflow with preprocessing and model
stroke_workflow <- workflow() %>%
  add_model(stroke_model_spec) %>%
  add_recipe(stroke_recipe) %>%
  fit(data = train_data)  # Now fit the workflow

# Define the Vetiver model using the trained workflow
v <- vetiver_model(stroke_workflow, model_name = "stroke_model")

# Save the model using a temporary board
board <- pins::board_temp()
vetiver_pin_write(board, v)

# Deploy API using Plumber
pr() %>%
  vetiver_api(v) %>%
  pr_run(port = 8080)


```




# Task Five: Findings and Conclusions
































